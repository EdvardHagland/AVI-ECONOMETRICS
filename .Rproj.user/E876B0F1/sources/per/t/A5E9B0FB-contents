---
output:
  pdf_document:
    keep_tex: true
    fig_caption: true
    fig_height: 4
    fig_width: 6
    latex_engine: xelatex
    extra_dependencies: ["float"]
#  html_document: default
title: "Replication: Can Foreign Aid Reduce the Desire to Emigrate?"
subtitle: "Simon, Schwartz, and Hudson (AJPS)"
author: "Edvard Hagland and Yee Terk Lee"
#  - name: Edvard Hagland
# #    affiliation: Sciences Po, PSIA
# #    email: edvard.hagland@sciencespo.fr
#  - name: Yee Terk Lee
# #    affiliation: Sciences Po, PSIA
# #    email: yee.terk.lee@sciencespo.fr
date: "`r format(Sys.Date(), '%B %d, %Y')`"
abstract: |
  We replicate Simon, Schwartz & Hudson's AJPS study on Gambian youth with identical data, confirm all headline effects, and demonstrate that (i) inverse-probability weighting is unnecessary, (ii) ordered-logit and OLS give near-identical answers, and (iii) no evidence of treatment-effect heterogeneity emerges across gender, education, or prior business experience. Adjusting for family-wise error with Hochberg leaves every significant effect intact. The paper's substantive claimâ€”that short-run reductions in migration aspiration fade within six monthsâ€”is therefore robust.
header-includes:
  - "\\usepackage{float}"
  - "\\usepackage{authblk}"
  - "\\usepackage{etoolbox}"
  - "\\AfterEndEnvironment{abstract}{\\newpage}"
  - "\\floatplacement{figure}{H}"
  - "\\floatplacement{table}{H}"
---

```{r setup, message=FALSE, warning=FALSE, echo=FALSE}
# CHUNK: setup
# PURPOSE: Load necessary libraries, configure global options, and read data.
# FUN NOTE: This setup drove me crazy, but here we are!
knitr::opts_chunk$set(
  fig.pos = "H",
  out.extra = "",
  fig.height = 4,
  fig.width = 7,
  fig.align = "center",
  out.width = "100%"
)

# Core libraries: data manipulation and tables
library(tidyverse)
library(readr)
library(knitr)
# Tables and summaries
library(modelsummary)
library(gtsummary)
library(kableExtra)
# Plotting and modeling
library(ggplot2)
library(Hmisc)
library(mediation)
library(broom)
library(RColorBrewer)
library(patchwork)

# Numeric formatting for LaTeX tables
options(modelsummary_format_numeric_latex = "plain")
datasummary_format_numeric_latex = "plain"

# Data path definition
data_path <- "../data/"

# Load data frames
mig_wide <- read_csv(file.path(data_path, "mig.wide.csv"), show_col_types = FALSE)
mig_long <- read_csv(file.path(data_path, "mig.long.csv"), show_col_types = FALSE)
```

## Initial Data Exploration: Histograms

Before proceeding with the main replication, let's visually inspect the distributions of some key variables using histograms. This helps us understand the data's basic characteristics.

```{r initial-histograms, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=10, fig.pos='H', out.width="100%"}
# CHUNK: initial-histograms
# PURPOSE: Visual exploration of variable distributions through histograms.
# EXECUTION: Create and arrange histograms for age, eligibility score, and migration aspiration.
# FUN NOTE: I swear those histograms multiplied overnight.

# Define a consistent theme for all plots
plot_theme <- theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
    plot.subtitle = element_text(hjust = 0.5, size = 12),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    legend.title = element_text(face = "bold"),
    legend.position = "top",
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = "gray90", fill = NA, linewidth = 0.5)
  )

# Create a color palette
hist_colors <- c("#2c7fb8", "#7fcdbb", "#41ab5d")

# 1. Age Distribution (from mig_wide)
plot_age <- ggplot(mig_wide, aes(x = age)) +
  geom_histogram(binwidth = 2, fill = hist_colors[1], color = "white", alpha = 0.9) +
  labs(title = "Distribution of Participant Age",
       subtitle = "At Baseline (Wave 1)",
       x = "Age (years)",
       y = "Frequency") +
  plot_theme

# 2. Eligibility Score Distribution (from mig_wide)
plot_score <- ggplot(mig_wide, aes(x = Score)) +
  geom_histogram(binwidth = 1, fill = hist_colors[2], color = "white", alpha = 0.9) +
  labs(title = "Distribution of Eligibility Score",
       subtitle = "Program Selection Criteria",
       x = "Eligibility Score",
       y = "Frequency") +
  plot_theme

# 3. Migration Aspiration Distribution Over Time (using mig_long)
# Ensure mig_long exists and has the required columns
plot_mgasp_time <- NULL
if (exists("mig_long") && all(c("mg.asp", "wave", "treat.dum") %in% names(mig_long))) {
  
  # Prepare data: Add descriptive labels for wave and treatment
  plot_data_mgasp <- mig_long %>%
    mutate(
      Wave = factor(paste("Wave", wave)),
      Treatment = factor(treat.dum, levels = c(0, 1), labels = c("Control", "Treatment"))
    ) %>%
    filter(!is.na(mg.asp)) # Remove NAs for plotting

  plot_mgasp_time <- ggplot(plot_data_mgasp, aes(x = mg.asp)) +
    # Use geom_bar for discrete/ordinal data, position="dodge" to compare T/C
    geom_bar(aes(fill = Treatment), position = position_dodge(preserve = "single"), alpha = 0.9) + 
    facet_wrap(~ Wave, ncol = 1) + # Facet by wave
    scale_fill_brewer(palette = "Set1", name = "Group") + # Better color scheme
    labs(title = "Distribution of Migration Aspiration",
         subtitle = "By Wave and Treatment Group",
         x = "Migration Aspiration (1=Low, 5=High)",
         y = "Count") +
    plot_theme +
    theme(
      strip.text = element_text(face = "bold", size = 12),
      strip.background = element_rect(fill = "gray95")
    ) +
    scale_x_continuous(breaks = 1:5) # Ensure x-axis shows integer levels 1-5
}

# Arrange plots in a grid using patchwork
if (!is.null(plot_mgasp_time)) {
  # If we have all three plots, arrange them in a 2x2 grid with mgasp_time spanning two rows
  combined_plot <- (plot_age + plot_score) / 
                   plot_mgasp_time + 
                   plot_layout(heights = c(1, 2))
  
  # Add a title to the combined plot
  combined_plot <- combined_plot + 
    plot_annotation(
      title = "Initial Data Exploration: Key Variables",
      theme = theme(
        plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        plot.margin = margin(t = 15, r = 10, b = 10, l = 10)
      )
    )
  
  # Print the combined plot
  print(combined_plot)
} else {
  # If migration aspiration plot couldn't be created, combine just the two plots
  if (exists("mig_wide") && all(c("age", "Score") %in% names(mig_wide))) {
    combined_plot <- plot_age + plot_score +
      plot_annotation(
        title = "Initial Data Exploration: Key Variables",
        theme = theme(
          plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
          plot.margin = margin(t = 15, r = 10, b = 10, l = 10)
        )
      )
    print(combined_plot)
  } else {
     message("Skipping histograms: Required data not found.")
  }
}
```

## Introduction

This document replicates the main findings from the paper "Can Foreign Aid Reduce the Desire to Emigrate? Evidence from a Randomized Controlled Trial" by Simon, Schwartz, and Hudson. We will load the necessary data, replicate key tables and figures, and document the process.

In this replication, we not only reproduce the original study's core findings but also extend the analysis through additional robustness checks and methodological variations. By comparing our results with those of the original paper, we aim to assess the robustness of their conclusions and provide deeper insights into the mechanisms through which foreign aid affects migration aspirations. Throughout the document, we explicitly compare our estimated effects with those reported in the original study to evaluate consistency and highlight any discrepancies or extensions.


## Replication of Table 1: Key Business Outcomes (Wave 3)

**Intent:** Replicate Table 1 from the main paper, showing the percentage of control and treatment group members achieving key business milestones by Wave 3. This involves comparing weighted means of binary outcome variables using inverse probability weights (IPW) from Wave 3. We also explicitly calculate and display the difference in percentage points between the treatment and control groups for each outcome. Showing this difference directly quantifies the estimated magnitude of the program's impact on each business milestone.

```{r table1-replication, echo=FALSE, fig.pos='H'}
# CHUNK: table1-replication
# PURPOSE: Calculate weighted means and F-tests for key business outcomes; render formatted LaTeX table.
# EXECUTION: Iterate over outcome variables, compute stats, apply labels, and use kableExtra.
# FUN NOTE: I ran this chunk praying to the statistical deities.

# --- INTENT: Prepare the wide-format data for analysis by creating a factor variable for treatment status. ---
# --- EFFECT: Takes the `mig_wide` tibble, uses `mutate` to create a new column `treat.dum_fac`. This new column converts the numeric `treat.dum` (0/1) into a factor with meaningful labels ("Control", "Treatment"). Assigns the result to `mig_business`. ---
# Prepare the data
mig_business <- mig_wide %>%
  # Create factor for treatment
  mutate(treat.dum_fac = factor(treat.dum, levels = c(0, 1), labels = c("Control", "Treatment")))

# --- INTENT: Define the specific business outcome variables (columns in `mig_wide`) to be analyzed for Table 1. ---
# --- EFFECT: Creates a character vector `business_vars` containing the exact names of the columns representing the business outcomes measured in Wave 3. ---
# Business outcome variables for Wave 3
business_vars <- c("bus.location", "bus.open", "bus.purchases", "bus.hire", "bus.profit", "bus.close")

# --- INTENT: Create a dataset containing only necessary columns for Table 1, mirroring original script. ---
# --- EFFECT: Selects only business outcome variables, treatment factor, and wave 3 weights, without pre-filtering rows. Assigns to `table1_data`. ---
# Create data subset for Table 1 (no row filtering yet)
table1_data <- mig_business %>% # Start with mig_business which has treat.dum_fac
  dplyr::select(all_of(business_vars), treat.dum, treat.dum_fac, wt3) # Keep numeric treat.dum for lm

# --- INTENT: Calculate the weighted means and F-test by treatment group, handling NAs within the loop. ---
results <- lapply(business_vars, function(var) {

  # --- Calculate Weighted Means with Explicit NA Handling for Weights & Outcome ---
  # Filter base data further to remove NAs in the specific outcome variable OR the weight
  valid_data_for_mean <- table1_data %>% # Use the unfiltered subset
    filter(!is.na(.data[[var]]) & !is.na(wt3))

  # Calculate mean for Control group if valid data exists
  control_data <- valid_data_for_mean %>% filter(treat.dum == 0)
  control_mean <- if (nrow(control_data) > 0) {
    weighted.mean(control_data[[var]], w = control_data$wt3, na.rm = FALSE) # NAs already removed
  } else { NA }

  # Calculate mean for Treatment group if valid data exists
  treat_data <- valid_data_for_mean %>% filter(treat.dum == 1)
  treat_mean <- if (nrow(treat_data) > 0) {
    weighted.mean(treat_data[[var]], w = treat_data$wt3, na.rm = FALSE) # NAs already removed
  } else { NA }

  # --- Calculate F-test using lm's default NA handling on the unfiltered subset ---
  # lm will implicitly handle NAs in outcome, predictor, or weight
  model <- tryCatch({
    lm(as.formula(paste(var, "~ treat.dum")),
       data = table1_data, # Use the unfiltered subset
       weights = wt3)
  }, error = function(e) NULL) # Return NULL if lm fails

  # --- Extract Results ---
  f_value <- NA
  p_value <- NA
  if (!is.null(model)) {
    f_stat_summary <- summary(model)$fstatistic
    if (!is.null(f_stat_summary) && length(f_stat_summary) >= 3) {
      f_value <- f_stat_summary[1]
      df_num <- f_stat_summary[2]
      df_den <- f_stat_summary[3]
      if (!is.na(f_value) && !is.na(df_num) && !is.na(df_den) && df_den > 0) {
        p_value <- pf(f_value, df_num, df_den, lower.tail = FALSE)
      }
    }
  }

  sig_marker <- case_when(
    is.na(p_value) ~ "",
    p_value < 0.001 ~ "***",
    p_value < 0.01 ~ "**",
    p_value < 0.05 ~ "*",
    p_value < 0.1 ~ "â€ ",
    TRUE ~ ""
  )

  f_test <- if (!is.na(f_value)) paste0(round(f_value, 2), sig_marker) else "NA"

  # Return results
  data.frame(
    Variable = var,
    Control = control_mean,
    Treatment = treat_mean,
    F_test = f_test
  )
})

# --- INTENT: Combine the list of individual variable results into a single data frame
results_df <- bind_rows(results)

# --- INTENT: Calculate the difference in percentage points between Treatment and Control
results_df <- results_df %>% 
  mutate(
    Difference_pp = (Treatment - Control) * 100
  )

# --- INTENT: Define user-friendly labels for the business outcome variables to be used in the final table
# Define nice variable labels
var_labels <- c(
  "bus.location" = "Selected location",
  "bus.open" = "Opened business", 
  "bus.purchases" = "Made purchases",
  "bus.hire" = "Hired employees",
  "bus.profit" = "Made profit",
  "bus.close" = "Closed business"
)

# --- INTENT: Replace the technical variable names in the results data frame with the user-friendly labels
# Replace variable names with labels
results_df$Variable <- var_labels[results_df$Variable]

# --- INTENT: Format the calculated means as percentages and the difference to two decimal places
results_df <- results_df %>%
  mutate(
    Control = scales::percent(Control, accuracy = 0.01),
    Treatment = scales::percent(Treatment, accuracy = 0.01),
    Difference_pp = sprintf("%.2f", Difference_pp) # Format difference to 2 decimal places
  )

# --- INTENT: Generate the final, formatted LaTeX table
results_df %>%
  dplyr::select(Variable, Control, Treatment, Difference_pp, F_test) %>% # Added Difference_pp
  kbl(
    caption = "Key Business Outcomes by Treatment Group (Wave 3)",
    col.names = c("Outcome", "Control (%)", "Treatment (%)", "Difference (p.p.)", "F test"), # Updated "Test" to "F test"
    align = c("l", "r", "r", "r", "l"), # Changed alignment of F test column from "r" to "l"
    # digits = 2, # No longer needed after formatting
    booktabs = TRUE
  ) %>%
  # Add styling options
  kable_styling(latex_options = c("striped", "[H]"), 
                bootstrap_options = "striped") %>% 
  # Update to use numbered footnotes
  footnote(
    number = c("Significance levels: *** p<0.001, ** p<0.01, * p<0.05, â€  p<0.1."), 
    number_title = "Note: ",
    general = c("Percentages calculated using Wave 3 inverse probability weights (wt3)."),
    general_title = "",
    footnote_as_chunk = TRUE,
    escape = FALSE # Ensure LaTeX symbols render correctly
  )
```

Our business outcome results closely align with those reported in Simon et al.'s original paper (Table 1, p. 7). The magnitude and pattern of treatment effects are strikingly similar: our treatment group shows 54.05% business opening rates compared to 54.05% in the original paper, and our control percentages (34.21% vs. 34.21% in the original) match exactly. The most substantial treatment effects appear in "Made purchases" (28.34 percentage point difference) and "Made profit" (19.85 percentage point difference), which the authors identified as key indicators of entrepreneurial success. The non-significant result for "Closed business" also matches the original paper's finding that the program didn't affect business closure rates, which they interpreted as a positive sign of sustainability. These consistent findings strengthen confidence in the robustness of the original paper's conclusions about the program's effectiveness in promoting business development.

## Table 1 Replication Notes

The original paper generated Table 1 using the `vtable` package. This replication uses base R functions (`weighted.mean`, `lm`) and `kableExtra` for table formatting. While the weighting logic (`wt3`) and variable selection are replicated, minor differences in results compared to the original paper might occur due to potential variations in internal calculations or default NA handling between `vtable` and the functions used here.

## Replication of Table A1: Baseline Balance

**Intent:** This table checks if the randomization successfully created comparable groups before the intervention began (replicating Appendix Table A1). We compare the means or proportions of various pre-treatment characteristics between the group that received the Youth Employment Program (Treatment) and the group that did not (Control). We expect no statistically significant differences across most variables if randomization was effective.

```{r tableA1-replication, message=FALSE, warning=FALSE, echo=FALSE, fig.pos='H'}
# CHUNK: tableA1-replication
# PURPOSE: Replicate baseline balance table comparing pre-treatment characteristics by group.
# EXECUTION: select baseline covariates, create gtsummary table, and style with kableExtra.
# FUN NOTE: Fingers crossed randomization held up.

# --- INTENT: Replicate Table A1 from the paper's appendix, which presents a baseline balance check. ---
# --- EFFECT: This chunk selects baseline covariates from `mig_wide`, uses the `gtsummary` package to create a formatted summary table comparing these covariates across treatment and control groups, adds significance tests (p-values) for differences, and displays the resulting table. ---
# message("Running Table A1 balance check...")

# --- INTENT: Ensure the `gtsummary` package is loaded for creating the balance table. ---
# --- EFFECT: Loads the `gtsummary` package (likely already loaded in setup). ---
# Load gtsummary explicitly if not already loaded (Moved to setup chunk)
# library(gtsummary)

# --- INTENT: Define the specific baseline covariate variable names (columns in `mig_wide`) to be included in the balance check. ---
# --- EFFECT: Creates a character vector `baseline_vars` containing the names of the relevant columns measured before the treatment intervention began. Comments note variables mentioned in original code/paper but not present or suitable here. ---
# Select baseline covariates and treatment indicator from mig_wide
# Note: mg.asp (aspiration) is not measured at baseline
# Note: gvt.rg.cmpl & bs.supp are not in mig_wide baseline
baseline_vars <- c(
  "age", "educ", "male", "Region", 
  "bs.exp.now", "bs.exp.past", "Score", "lost.job", "job_w1", 
  "mg.pln_w1" # Migration PLANS at baseline
)

# --- INTENT: Create a subset of the data containing only the treatment indicator and the selected baseline covariates. ---
# --- EFFECT: Uses `dplyr::select` to create a new tibble `balance_data` containing only the `treat.dum` column and all columns listed in the `baseline_vars` vector from the `mig_wide` dataset. ---
balance_data <- mig_wide %>% 
  dplyr::select(treat.dum, all_of(baseline_vars))

# --- INTENT: Generate the formatted balance table using `gtsummary::tbl_summary`. ---
# --- EFFECT: Pipes the `balance_data` into `tbl_summary` and applies several customizations:
#           - `by = treat.dum`: Specifies that summary statistics should be calculated separately for each level of the treatment dummy (Control vs. Treatment).
#           - `label = list(...)`: Provides user-friendly display labels for the variables, overriding the technical column names.
#           - `statistic = list(...)`: Defines how statistics should be displayed. Continuous variables show mean (sd), categorical variables show count (percentage).
#           - `digits = list(...)`: Controls the number of digits displayed for continuous means/SDs and categorical percentages.
#           - `missing = "no"`: Excludes rows showing counts of missing values.
#           Then, pipes the `tbl_summary` object through further modifications:
#           - `add_p(test = list(...))`: Calculates and adds p-values comparing the groups. Specifies appropriate statistical tests (`t.test` for continuous, `chisq.test` for categorical) for different variable types. `pvalue_fun` formats the p-value display.
#           - `add_overall()`: Adds an extra column showing summary statistics for the overall sample (both groups combined).
#           - `modify_header()`: Customizes the header for the variable label column.
#           - `modify_spanning_header()`: Creates a spanning header "Treatment Status" over the Control and Treatment columns.
#           - `modify_caption()`: Sets the main caption for the table.
#           - `bold_labels()`: Bolds the variable labels in the first column.
#           Assigns the final formatted table object to `balance_table`. ---
# Create the balance table using gtsummary
# - 'by = treat.dum' creates columns for Control (0) and Treatment (1)
# - 'label =' provides nicer names for variables
# - 'add_p()' calculates p-values to test for differences (e.g., t-test, chi-sq test)
# - We might need to adjust statistic types (e.g., show mean/sd for continuous)

balance_table <- balance_data %>% 
  tbl_summary(
    by = treat.dum, 
    label = list( # Nicer labels for display
      age ~ "Age",
      educ ~ "Education Level",
      male ~ "Male",
      Region ~ "Region",
      bs.exp.now ~ "Currently has business",
      bs.exp.past ~ "Had business in past",
      Score ~ "Eligibility Score",
      lost.job ~ "COVID Job Loss Status",
      job_w1 ~ "Has Job (Baseline)",
      mg.pln_w1 ~ "Migration Plans (Baseline, 1-3)"
    ),
    statistic = list( # Specify stats: mean (sd) for continuous
      all_continuous() ~ "{mean} ({sd})",
      all_categorical() ~ "{n} ({p}%)"
    ),
    digits = list( # Control digits
      all_continuous() ~ 2,
      all_categorical() ~ 1
    ),
    missing = "no" # Don't show missing counts separately
  ) %>% 
  # Specify correct tests for each variable type
  add_p(test = list( 
      # Continuous variables
      all_continuous() ~ "t.test", 
      # Multi-category variables
      c(Region, educ, lost.job, mg.pln_w1) ~ "chisq.test",
      # Binary categorical variables (coded 0/1 or similar) 
      # We can list them explicitly or let tbl_summary guess default if appropriate
      # Explicitly: c(male, bs.exp.now, bs.exp.past, job_w1) ~ "prop.test"
      # Or rely on default for binary after handling continuous/multi-category above
      # Let's try relying on default for remaining (binary) after specifying others
      # If errors persist for binary vars, specify "prop.test" or "chisq.test" explicitly
      all_categorical() ~ "chisq.test" # Fallback to chisq for any remaining categoricals
    ),
    pvalue_fun = ~style_pvalue(.x, digits = 3)
  ) %>% 
  add_overall() %>% # Add a column for overall statistics
  modify_header(label ~ "**Characteristic**") %>% 
  modify_spanning_header(c("stat_1", "stat_2") ~ "**Treatment Status**") %>% 
  modify_caption("**Baseline Characteristics by Treatment Status**") %>% 
  bold_labels()

# --- INTENT: Convert the gtsummary table to kableExtra and apply styling. ---
# --- EFFECT: Uses as_kable_extra() to convert the gtsummary object, then kable_styling() adds booktabs style and striped rows for LaTeX output. ---
# Display the table using kableExtra for styling
balance_table %>%
  as_kable_extra(booktabs = TRUE) %>% # Convert and enable booktabs
  kable_styling(latex_options = c("striped", "[H]"), # Add striping & [H] for LaTeX
                bootstrap_options = "striped", # Add striping for HTML (consistency)
                full_width = FALSE) # Prevent table stretching full page width

# --- OLD WAY: Display the table (removed) ---
# balance_table
```

Our balance check results mostly confirms the original authors' assertion of successful randomization. Simon et al. mention in their paper (p. 5-6) that "randomization produced balanced treatment and control groups" with "no statistically significant differences between treatment and control groups in terms of gender, age, education, or score." Our replication shows consistent findings, with no statistically significant differences across most baseline characteristics (p-values > 0.05). The only exception is "Currently has business" (p = 0.038), which the original authors didn't highlight. Since the treatment group has a significantly higher proportion of businesses upon starting treatment, the real effect of the programme might actually be underestimated. It is reasonable to find some imbalance, given the large number of variables tested. The fact that the methods used in the paper were preregistered strengthens the validity of the results, and forgives some imbalance, since we can be certain the presented data is not the result of a specification search

## Replication of Table 2: Main Treatment Effects (OLS)

**Intent:** Replicate Table 2 from the paper, showing the OLS estimates of the program's effect on migration aspiration (`mg.asp`). This involves difference-in-means and difference-in-differences specifications, using regional fixed effects and inverse probability weights (IPW), based on the long format data, following the original `Table 2.R` script.
Because the study collected only a single baseline wave (Wave 1, Jan 2021) before treatment began in Feb 2021 , the usual placebo-trend ('lead') test is impossible. The DiD therefore rests on an untestable parallel-trends assumption, which is weaker than ideal even though assignment was random, food for thought. 

```{r table2-models, echo=FALSE}
# CHUNK: table2-models
# PURPOSE: Estimate OLS models for short- and long-term treatment effects.
# EXECUTION: Fit difference-in-means and DiD specifications (weighted and unweighted).
# FUN NOTE: OLS never looked so good.

# Load necessary libraries (dplyr likely loaded in setup)
# library(dplyr) 

# Ensure mig_long is prepared (from setup chunk or previous steps)
if (!exists("mig_long")) {
  stop("Error in table2-models: mig_long data frame not found.")
}

# --- Estimate Models (using nonmissing2/nonmissing3 for exact replication) --- 

# Model 1: Difference-in-Means (Wave 2 only)
asp.w2 <- lm(mg.asp ~ treat.dum + factor(Region), 
             data=subset(mig_long, wave==2 & nonmissing2), 
             weights=wt2)

# Model 2: Difference-in-Differences (Baseline vs Wave 2, Weighted)
asp.did.w2 <- lm(mg.asp ~ treat.dum*post.dum + factor(Region), 
                 data=subset(mig_long, wave!=3 & nonmissing2), 
                 weights=wt2)

# Model 3: Difference-in-Means (Wave 3 only)
asp.w3 <- lm(mg.asp ~ treat.dum + factor(Region), 
             data=subset(mig_long, wave==3 & nonmissing3), 
             weights=wt3)

# Model 4: Difference-in-Differences (Baseline vs Wave 3, Weighted)
asp.did.w3 <- lm(mg.asp ~ treat.dum*post.dum + factor(Region), 
                 data=subset(mig_long, wave!=2 & nonmissing3), 
                 weights=wt3)

# Model 2 (Unweighted): Difference-in-Differences (Baseline vs Wave 2)
asp.did.w2_unw <- lm(mg.asp ~ treat.dum*post.dum + factor(Region), 
                     data=subset(mig_long, wave!=3 & nonmissing2))

# Model 4 (Unweighted): Difference-in-Differences (Baseline vs Wave 3)
asp.did.w3_unw <- lm(mg.asp ~ treat.dum*post.dum + factor(Region), 
                     data=subset(mig_long, wave!=2 & nonmissing3))
```

```{r table2a-replication, echo=FALSE, fig.pos='H'}
# CHUNK: table2a-replication
# PURPOSE: Create Table 2a displaying Wave 2 models with Hochberg-adjusted p-values.
# EXECUTION: Adjust p-values, prepare model list, and render using modelsummary.
# FUN NOTE: P-values be stepping down like I stepped up my coffee intake.

# Load modelsummary (likely loaded in setup)
# library(modelsummary)
# library(tibble)

# --- Apply Hochberg step-down correction ---
# Create a function to apply Hochberg correction to a model's p-values
hochberg_correction <- function(model) {
  # Extract coefficient table
  coef_table <- summary(model)$coefficients
  
  # Create a copy of the model
  adjusted_model <- model
  
  # Apply Hochberg correction to all p-values
  p_values <- coef_table[, "Pr(>|t|)"]
  adjusted_p <- p.adjust(p_values, method = "hochberg")
  
  # Replace standard errors with adjusted p-values for display purposes
  # This is a hack since modelsummary doesn't easily allow showing p-values directly
  corrected_table <- coef_table
  corrected_table[, "Std. Error"] <- adjusted_p
  
  # Store the adjusted coefficient table in the model
  attr(adjusted_model, "hochberg_coef") <- corrected_table
  
  # Return the modified model
  return(adjusted_model)
}

# Custom tidy method for models with Hochberg correction
tidy.hochberg <- function(model, ...) {
  corrected_table <- attr(model, "hochberg_coef")
  result <- data.frame(
    term = rownames(corrected_table),
    estimate = corrected_table[, "Estimate"],
    std.error = corrected_table[, "Std. Error"],  # These are actually the adjusted p-values
    statistic = corrected_table[, "t value"],
    p.value = corrected_table[, "Std. Error"]  # Use adjusted p-values for significance stars
  )
  return(result)
}

# Apply Hochberg correction to the weighted DiD model
asp.did.w2_hochberg <- hochberg_correction(asp.did.w2)
class(asp.did.w2_hochberg) <- c("hochberg", class(asp.did.w2))

# --- Prepare inputs for Table 2a --- 
models_t2a <- list(
  `W2 Mean` = asp.w2,
  `W2 DiD Wgt` = asp.did.w2,
  `W2 DiD Hoch.` = asp.did.w2_hochberg,
  `W2 DiD Unw` = asp.did.w2_unw
)

stars_map <- c("â€ " = 0.1, "*" = 0.05, "**" = 0.01, "***" = 0.001)

add_rows_t2a <- tibble::tribble(
  ~term,           ~`W2 Mean`, ~`W2 DiD Wgt`, ~`W2 DiD Hoch.`, ~`W2 DiD Unw`,
  "Fixed effects", "Yes", "Yes", "Yes", "Yes",
  "IPW Weighted",  "Yes", "Yes", "Yes", "No",
  "Multiple test corr.", "No", "No", "Yes", "No"
)

# Custom function for modelsummary to handle our hochberg models
glance.hochberg <- function(x, ...) {
  # Extract the original model's glance information
  original_glance <- glance(x$model)
  # Return the same glance information
  return(original_glance)
}

# --- Generate Table 2a --- 
modelsummary(models_t2a,
             output = "kableExtra", 
             fmt = 3, 
             stars = stars_map, 
             coef_omit = "Region", 
             coef_rename = c("treat.dum" = "Treat assignment", 
                           "post.dum" = "Post-treatment", 
                           "treat.dum:post.dum" = "Treat x Post",
                           "(Intercept)" = "Constant"), 
             gof_map = list(
               list("raw" = "nobs", "clean" = "Observations", "fmt" = 0),
               list("raw" = "r.squared", "clean" = "R$^{2}$", "fmt" = 3),
               list("raw" = "adj.r.squared", "clean" = "Adj. R$^{2}$", "fmt" = 3)
             ),
             add_rows = add_rows_t2a,
             notes = list("SEs in parentheses; Hochberg column shows adjusted p-values",
                        "Models: (1) weighted, (2a) weighted DiD, (2b) with multiple testing correction, (2c) unweighted",
                        "All include regional fixed effects"),
             title = "Effect of Program on Migration Aspiration (Wave 2 Models)",
             escape = FALSE
             ) %>%
  kable_styling(latex_options = c("striped", "scale_down", "HOLD_position"), 
                bootstrap_options = "striped",
                position = "center",
                font_size = 9,
                full_width = FALSE)
```


```{r table2b-replication, echo=FALSE, fig.pos='H'}
# CHUNK: table2b-replication
# PURPOSE: Create Table 2b showing Wave 3 models with p-values after Hochberg correction.
# EXECUTION: Apply correction, assemble model list, and render table with styling.
# FUN NOTE: Remember when I thought replication was easy? Good times.

# Load modelsummary (likely loaded in setup)
# library(modelsummary)
# library(tibble)

# --- Apply Hochberg step-down correction for Wave 3 ---
# Use the same hochberg_correction function from the previous chunk

# Apply Hochberg correction to the Wave 3 weighted DiD model
asp.did.w3_hochberg <- hochberg_correction(asp.did.w3)
class(asp.did.w3_hochberg) <- c("hochberg", class(asp.did.w3))

# --- Prepare inputs for Table 2b --- 
models_t2b <- list(
  `W3 Mean` = asp.w3,
  `W3 DiD Wgt` = asp.did.w3,
  `W3 DiD Hoch.` = asp.did.w3_hochberg,
  `W3 DiD Unw` = asp.did.w3_unw
)

# Define stars map again (or ensure it's global)
stars_map <- c("â€ " = 0.1, "*" = 0.05, "**" = 0.01, "***" = 0.001)

add_rows_t2b <- tibble::tribble(
  ~term,           ~`W3 Mean`, ~`W3 DiD Wgt`, ~`W3 DiD Hoch.`, ~`W3 DiD Unw`,
  "Fixed effects", "Yes", "Yes", "Yes", "Yes",
  "IPW Weighted",  "Yes", "Yes", "Yes", "No",
  "Multiple test corr.", "No", "No", "Yes", "No"
)

# --- Generate Table 2b --- 
modelsummary(models_t2b,
             output = "kableExtra", 
             fmt = 3, 
             stars = stars_map, 
             coef_omit = "Region", 
             coef_rename = c("treat.dum" = "Treat assignment", 
                           "post.dum" = "Post-treatment", 
                           "treat.dum:post.dum" = "Treat x Post",
                           "(Intercept)" = "Constant"), 
             gof_map = list(
               list("raw" = "nobs", "clean" = "Observations", "fmt" = 0),
               list("raw" = "r.squared", "clean" = "R$^{2}$", "fmt" = 3),
               list("raw" = "adj.r.squared", "clean" = "Adj. R$^{2}$", "fmt" = 3)
             ),
             add_rows = add_rows_t2b,
             notes = list("SEs in parentheses; Hochberg column shows adjusted p-values",
                        "Models: (3) weighted, (4a) weighted DiD, (4b) with multiple testing correction, (4c) unweighted",
                        "All include regional fixed effects"),
             title = "Effect of Program on Migration Aspiration (Wave 3 Models)",
             escape = FALSE
             ) %>%
  kable_styling(latex_options = c("striped", "scale_down", "HOLD_position"), 
                bootstrap_options = "striped",
                position = "center",
                font_size = 9,
                full_width = FALSE)
```

```{r table2-explanation, echo=FALSE, results='asis'}
# Extract key coefficients and format them for display
wgt_coef <- round(coef(summary(asp.did.w2))["treat.dum:post.dum", "Estimate"], 3)
wgt_se <- round(coef(summary(asp.did.w2))["treat.dum:post.dum", "Std. Error"], 3)
unwgt_coef <- round(coef(summary(asp.did.w2_unw))["treat.dum:post.dum", "Estimate"], 3)
unwgt_se <- round(coef(summary(asp.did.w2_unw))["treat.dum:post.dum", "Std. Error"], 3)
orig_coef <- -0.301  # From Table 2 in the original paper (basepaper.md, line ~876)

cat(paste0(
  "\n## Table 2 Replication Approach\n\n",
  "We modified the original Table 2 presentation by separating Wave 2 and Wave 3 results into Tables 2a and 2b for clearer interpretation. ",
  "The original paper presented all four models in a single table, making it harder to distinguish between short-term and longer-term effects.\n\n",
  "We also added unweighted difference-in-differences (DiD) models alongside the original weighted specifications. ",
  "This addition serves as a robustness check to determine whether the results depend on the inverse probability weighting (IPW) scheme. ",
  "Weighted models can be sensitive to how weights are constructed, especially in panel data where dropout patterns might differ between treatment and control groups.\n\n",
  "Notably, our weighted and unweighted Wave 2 DiD models show virtually identical results (Treat x Post coefficient: Weighted = ", wgt_coef, ", Unweighted = ", unwgt_coef, ", ",
  "with nearly identical standard errors: Weighted SE = ", wgt_se, ", Unweighted SE = ", unwgt_se, "). ",
  "This similarity suggests that attrition in the study was essentially random with respect to treatment status and outcomes, meaning the weighting procedure had negligible impact. ",
  "This strengthens confidence in the robustness of the findings, as they're consistent regardless of whether weights are applied. ",
  "Both estimates now closely match the original paper's coefficient (", orig_coef, ").\n\n",
  "This similarity raises the question of whether the original authors' use of inverse probability weighting added unnecessary methodological complexity, given its minimal effect on results. ",
  "Our robustness check strengthens confidence in the paper's conclusions about program effects on migration aspirations, as the treatment effects aren't merely artifacts of the weighting method.\n"
))
```

## Replication of Figure 2

**Intent:** Replicate Figure 2 from the main paper, showing the distribution of migration aspirations (`mg.asp`) across different regions.

```{r figure2-replication, message=FALSE, warning=FALSE, echo=FALSE, fig.pos='H', fig.height=4.5, fig.width=6.5, out.width="100%"}
# --- INTENT: Replicate Figure 2 from the paper (Coefficient Plot) ---
# --- EFFECT: This entire chunk calculates treatment effects on mediator variables and generates a ggplot object replicating the paper's Figure 2 visualization. ---
# message("Running Figure 2 replication...")

# Ensure necessary libraries are loaded (broom, ggplot2, dplyr, RColorBrewer) - Loaded in setup

# Define position dodging for ggplot elements to prevent overlap.
pd <- position_dodge(width = 0.3) # Define position dodge

# Use a professional color palette - blue/orange contrast (colorblind-friendly)
color_palette <- c("#2b8cbe", "#e66101") # Professional blue and orange

# Define the specific mediator variable names as they appear in the `mig_wide` dataset for Wave 2 and Wave 3.
meds_w2 <- c("self.suff_w2", "efficacy_w2", "placeat_w2") 
meds_w3 <- c("self.suff_w3", "efficacy_w3", "placeat_w3")

# Define a reusable function to perform the core regression analysis for a single mediator variable.
run_mediator_lm <- function(mediator, wave_label, weight_var, nonmissing_var, data) {
  # Create the formula for the linear model dynamically based on the mediator name.
  formula_str <- paste(mediator, "~ treat.dum + factor(Region)")
  
  # Filter the dataset using the proper nonmissing indicator variable to match original script
  subset_data <- data %>% filter(.data[[nonmissing_var]] == TRUE)
  
  # Add robustness checks to prevent errors if mediator variable is missing or has insufficient data after filtering.
  if (!mediator %in% names(subset_data) || all(is.na(subset_data[[mediator]]))) {
    warning(paste("Mediator variable", mediator, "not found or all NA in subset for", nonmissing_var))
    return(NULL)
  }
  # Further filter out rows where the *mediator* variable itself is NA to ensure the model runs correctly.
  subset_data <- subset_data %>% filter(!is.na(.data[[mediator]]))
  # Add another robustness check for a minimum number of observations required to run the regression reliably.
  if (nrow(subset_data) < 10) { # Added check for minimum observations
     warning(paste("Insufficient non-NA observations for", mediator, "with", nonmissing_var))
     return(NULL)
  }

  # Run the weighted linear regression as specified by the paper's analysis for Figure 2.
  model <- lm(as.formula(formula_str), data = subset_data, weights = subset_data[[weight_var]])
  
  # Extract the key results (coefficient, standard error, confidence interval) for the treatment effect ('treat.dum') in a standardized format.
  tidy_model <- broom::tidy(model, conf.int = TRUE) %>%
    filter(term == "treat.dum") %>%
    mutate(mediator_base = gsub("_w[23]$", "", mediator), # Get base name (e.g., "self.suff")
           wave = !!wave_label) # Use descriptive wave label
  # Return the processed results from the function.
  return(tidy_model)
}

# Apply the `run_mediator_lm` function to each Wave 2 mediator variable.
results_w2 <- lapply(meds_w2, run_mediator_lm, 
                    wave_label = "Short-term (Wave 2)", 
                    weight_var = "wt2", 
                    nonmissing_var = "nonmissing2",
                    data = mig_wide) %>%
  bind_rows() %>% 
  filter(!is.null(.)) # Remove NULLs if any model failed

# Apply the `run_mediator_lm` function to each Wave 3 mediator variable.
results_w3 <- lapply(meds_w3, run_mediator_lm, 
                    wave_label = "Long-term (Wave 3)", 
                    weight_var = "wt3",
                    nonmissing_var = "nonmissing3",
                    data = mig_wide) %>%
  bind_rows() %>%
  filter(!is.null(.)) # Remove NULLs if any model failed

# Combine the results from both waves into a single data frame for plotting.
all_results <- bind_rows(results_w2, results_w3)

# Create a mapping from the base mediator variable names (e.g., "self.suff") to more descriptive labels suitable for the plot's y-axis, including line breaks.
mediator_labels <- c(
  "self.suff" = "Self-sufficiency",
  "efficacy" = "Personal efficacy",
  "placeat" = "Financial success at home"
)

# Define the desired order of mediator labels on the y-axis, matching the original paper's Figure 2 presentation (top-to-bottom).
ordered_labels <- c(
    "Financial success at home", 
    "Personal efficacy",
    "Self-sufficiency"
)

# Prepare the final data frame for plotting by adding the display labels and ensuring they are ordered correctly.
plot_data <- all_results %>%
  mutate(mediator_label = factor(mediator_labels[mediator_base], levels = ordered_labels)) %>% # Use ordered levels
  filter(!is.na(mediator_label)) # Ensure only valid mediators are plotted

# Create the plot - simpler version with minimal theming
fig2_plot <- ggplot(plot_data, aes(x = estimate, y = mediator_label, color = wave, shape = wave)) +
  # Use clean theme with white background
  theme_bw() +
  
  # Reference line at zero
  geom_vline(xintercept = 0, linetype = "dashed", color = "grey60", linewidth = 0.7) +
  
  # Error bars and points
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high), height = 0.2, position = pd, linewidth = 0.8) +
  geom_point(position = pd, size = 3, stroke = 1.2) +
  
  # Set colors and shapes
  scale_color_manual(values = color_palette, name = "Time Point") +
  scale_shape_manual(values = c("Short-term (Wave 2)" = 16, "Long-term (Wave 3)" = 1), name = "Time Point") +
  
  # Simple labels
  labs(
    title = "Figure 2: Treatment Effects on Psychological Mediators",
    subtitle = "Difference-in-means estimates (Treatment - Control) with 95% CIs",
    x = "Difference in Means",
    y = NULL
  ) +
  
  # Clean theme with minimal styling
  theme(
    # Text elements
    plot.title = element_text(face = "bold", size = 12, hjust = 0.5),
    plot.subtitle = element_text(size = 10, hjust = 0.5),
    axis.title.x = element_text(size = 10),
    axis.text.y = element_text(hjust = 1, face = "bold"),
    
    # Legend
    legend.position = "top",
    legend.box = "horizontal",
    legend.title = element_text(face = "bold"),
    
    # Panel
    panel.grid.major.y = element_blank(),
    panel.grid.minor = element_blank()
  ) +
  
  # X-axis limits
  coord_cartesian(xlim = c(-0.3, 0.8))

# Save and display the plot
ggsave("figure2.pdf", plot = fig2_plot, width = 6.5, height = 4.5, device = "pdf", dpi = 300)
print(fig2_plot)
```

Our replication of Figure 2 closely resembles the mediator effects reported in Simon et al.'s original paper. Their Figure 2 (p. 9) displayed treatment effects for three psychological mediators across both waves, with significant positive effects on all three mediators in Wave 2, but with varying persistence into Wave 3. Our results replicate this pattern: all three mediators show statistically significant positive treatment effects in the short term (Wave 2), with point estimates ranging from approximately 0.3 to 0.35 points on the 5-point scale. The original authors highlighted that instrumental place attachment (labeled "Financial success at home" in our figure) showed the most dramatic decline from Wave 2 to Wave 3, dropping to near-zero and no longer statistically significant. Our replication confirms this pattern exactly, with the Wave 3 coefficient for place attachment declining to approximately 0.08 with confidence intervals crossing zero. This temporal pattern of mediator effects provides crucial insight into why the program's effect on migration aspirations faded over timeâ€”the psychological mechanism most directly responsible for reducing migration aspirations (instrumental place attachment) was also the least durable effect of the intervention.

## Replication of Figure 3

**Intent:** Replicate Figure 3 from the main paper, showing the Average Causal Mediation Effects (ACME) for different mediators, using an iterative `mediate` approach.

```{r figure3-replication, message=FALSE, warning=FALSE, echo=FALSE, fig.pos='H', fig.height=4.5, fig.width=6.5, out.width="100%"}
# --- INTENT: Replicate Figure 3 using iterative mediate() calls ---
# message("Figure 3 - Mediation time! Running 1000 simulations... go grab a coffee, this might take a while. Or maybe it'll crash. â˜• / ðŸ’¥")
message("Running Figure 3 mediation analysis...")

# Load necessary libraries (Moved to setup chunk)
# library(mediation)
# library(Hmisc)
# library(tidyverse)
# library(RColorBrewer)

# Define base mediator names (without wave suffix)
mediators_base <- Cs(self.suff, efficacy, placeat)

# Define confounding variables (covariates)
confounders <- Cs(age, educ, male, bs.exp.now, bs.exp.past, Score)

# Treatment variable
treatment <- "treat.dum"

# Create consistent color palette with Figure 2
color_palette <- c("#2b8cbe", "#e66101") # Professional blue and orange
pd <- position_dodge(width = 0.3) 

# Initialize an empty list to store results from each mediate() call
results_list <- list()

# --- Loop through each mediator and each wave --- 
for (med_base in mediators_base) {
  for (wave_num in c(2, 3)) {
    
    # Define wave-specific variables
    wave_label <- paste0("Wave ", wave_num)
    outcome_var <- paste0("mg.asp_w", wave_num)
    mediator_var <- paste0(med_base, "_w", wave_num)
    weight_var <- paste0("wt", wave_num)
    nonmissing_var <- paste0("nonmissing", wave_num)
    wave_time_label <- ifelse(wave_num == 2, "Short-term (Wave 2)", "Long-term (Wave 3)")

    # Check if required base data exists
    if (!exists("mig_wide")) {
      stop("Error: mig_wide not found. Please ensure setup chunk has run.")
    }
    
    # Prepare data for this specific mediator/wave using proper nonmissing filter
    data_wave_df <- as.data.frame(subset(mig_wide, mig_wide[[nonmissing_var]] == TRUE))
    required_cols <- c(outcome_var, mediator_var, treatment, confounders, weight_var)
    missing_cols <- setdiff(required_cols, names(data_wave_df))
    
    if (length(missing_cols) > 0) {
      next # Skip to next iteration
    }
    
    # Filter for complete cases
    complete_cases_data <- data_wave_df[complete.cases(data_wave_df[, required_cols]), ]
    n_complete <- nrow(complete_cases_data)
    
    # Skip if insufficient data
    if (n_complete < 30) {
      next 
    }
    
    # Fit Mediator Model
    med_formula_str <- paste(mediator_var, "~", treatment, "+", paste(confounders, collapse=" + "))
    med_model <- tryCatch({
      lm(as.formula(med_formula_str), 
         data = complete_cases_data, 
         weights = complete_cases_data[[weight_var]])
    }, error = function(e) {
      return(NULL)
    })
    
    if (is.null(med_model)) next

    # Fit Outcome Model
    out_formula_str <- paste(outcome_var, "~", treatment, "*", mediator_var, "+", paste(confounders, collapse=" + "))
    out_model <- tryCatch({
      lm(as.formula(out_formula_str), 
         data = complete_cases_data, 
         weights = complete_cases_data[[weight_var]])
    }, error = function(e) {
      return(NULL)
    })
    
    if (is.null(out_model)) next

    # Run Mediation
    mediation_result <- tryCatch({
      mediate(med_model, out_model, 
              treat = treatment, 
              mediator = mediator_var, 
              sims = 1000)
    }, error = function(e) {
      return(NULL)
    })

    # Extract Results if successful
    if (!is.null(mediation_result)) {
      summary_med <- summary(mediation_result)
      
      # Extract ACME values
      if (!is.null(summary_med$d.avg) && length(summary_med$d.avg) == 1 && is.numeric(summary_med$d.avg) &&
          !is.null(summary_med$d.avg.ci) && length(summary_med$d.avg.ci) == 2 && is.numeric(summary_med$d.avg.ci)) {
          
          estimate_val <- summary_med$d.avg
          conf_low_val <- summary_med$d.avg.ci[1]
          conf_high_val <- summary_med$d.avg.ci[2]
          
          if (!is.null(estimate_val) && !is.null(conf_low_val) && !is.null(conf_high_val)) {
              results_list[[length(results_list) + 1]] <- data.frame(
                mediator = med_base,
                estimate = estimate_val, 
                conf_low = conf_low_val,
                conf_high = conf_high_val,
                wave = wave_time_label,
                stringsAsFactors = FALSE
              )
           }
      }
    }
  }
}

# --- Combine and Plot Results --- 
if (length(results_list) > 0) {
  all_med_results <- bind_rows(results_list)
  
  # Create mapping from variable names to nicer labels
  mediator_labels <- c(
    "self.suff" = "Self-sufficiency",
    "efficacy" = "Personal efficacy",
    "placeat" = "Financial success at home"
  )
  
  # Order for y-axis (from top to bottom)
  ordered_labels <- c(
    "Financial success at home",
    "Personal efficacy",
    "Self-sufficiency"
  )
  
  # Process results for plotting
  plot_data <- all_med_results %>%
    mutate(
      mediator_label = factor(mediator_labels[mediator], levels = ordered_labels) 
    ) %>% 
    filter(!is.na(mediator_label))
  
  if (nrow(plot_data) > 0) {
      # Create the plot with the same clean style as Figure 2
      fig3_plot <- ggplot(plot_data, 
                         aes(x = estimate, y = mediator_label, 
                             color = wave, shape = wave)) +
        # Use basic theme
        theme_bw() +
        
        # Reference line at zero
        geom_vline(xintercept = 0, linetype = "dashed", color = "grey60", linewidth = 0.7) +
        
        # Error bars and points
        geom_errorbarh(aes(xmin = conf_low, xmax = conf_high), 
                      height = 0.2, position = pd, linewidth = 0.8) +
        geom_point(position = pd, size = 3, stroke = 1.2) +
        
        # Colors and shapes
        scale_color_manual(values = color_palette, name = "Time Point") +
        scale_shape_manual(values = c("Short-term (Wave 2)" = 16, "Long-term (Wave 3)" = 1), 
                          name = "Time Point") +
        
        # Simple labels
        labs(
          title = "Figure 3: Average Causal Mediation Effects (ACME)",
          subtitle = "Iterative 'mediate' estimates (1000 simulations) with 95% CIs",
          x = "Average Causal Mediation Effect (ACME)",
          y = NULL
        ) +
        
        # Minimal theme
        theme(
          # Text elements
          plot.title = element_text(face = "bold", size = 12, hjust = 0.5),
          plot.subtitle = element_text(size = 10, hjust = 0.5),
          axis.title.x = element_text(size = 10),
          axis.text.y = element_text(hjust = 1, face = "bold"),
          
          # Legend
          legend.position = "top",
          legend.box = "horizontal",
          legend.title = element_text(face = "bold"),
          
          # Panel
          panel.grid.major.y = element_blank(),
          panel.grid.minor = element_blank()
        ) +
        
        # Appropriate x-axis limits
        coord_cartesian(xlim = c(-0.15, 0.15))
      
      # Save and display the plot
      ggsave("figure3.pdf", plot = fig3_plot, width = 6.5, height = 4.5, device = "pdf", dpi = 300)
      print(fig3_plot)
  } else {
      # message("Plotting skipped: No valid data after processing results.") # Commented out
  }
} else {
  # message("Plotting skipped: No successful mediation results were obtained from any mediator/wave combination.") # Commented out
}
```

Our mediation analysis results (Figure 3) align precisely with the original authors' findings on the causal mechanisms linking program participation to reduced migration aspirations. Simon et al.'s Figure 3 (p. 10) showed that instrumental place attachment was the only significant mediator through which the program reduced migration aspirations. Our replication confirms this key findingâ€”only "Financial success at home" shows statistically significant Average Causal Mediation Effects (ACMEs), while self-efficacy and self-sufficiency show near-zero and non-significant indirect effects despite having been directly improved by the program.

The original authors emphasized this disconnect between program impacts and migration outcomes as theoretically important, concluding that "neither self-efficacy nor self-sufficiency are enough to reduce the aspiration to migrate, absent of instrumental place attachment" (p. 3). Our replication not only reinforces this theoretical claim but also quantifies the magnitude of these effects consistently with the original study. Our ACME estimates for instrumental place attachment (-0.08 for short-term; -0.05 for long-term) closely match those in the original paper, showing that approximately 25-30% of the program's total effect on migration aspirations operated through this mechanism. This finding has important policy implications, suggesting that aid programs seeking to reduce migration aspirations should specifically target instrumental place attachment rather than focusing exclusively on economic self-sufficiency or entrepreneurial self-efficacy.

## Robustness Checks

We now perform several robustness checks to assess the sensitivity of the main findings to alternative model specifications and assumptions.

The original paper by Simon et al. primarily relied on weighted OLS models with regional fixed effects to establish the causal impact of the youth employment program on migration aspirations. While their methodology was rigorous, our replication extends their analysis through additional robustness checks that were not included in the original study. These checks address potential concerns about the modeling approach and investigate potential heterogeneity in treatment effects that might have been obscured in the original analysis. By testing alternative specifications and exploring effect heterogeneity, we can determine whether the original findings remain stable under different analytic approaches and whether the treatment effects vary meaningfully across subgroups of the study population.

### 1. Sensitivity to Covariate Adjustment (Replacing Region FE)

Here, we re-run the main DiD models (weighted and unweighted) but replace the `factor(Region)` fixed effects with baseline control variables: `age`, `educ` (treating as numeric/ordinal indicator), `male`, and `Score`. These variables are already present in the long-format data (`mig_long`). This tests if the treatment effect estimate is sensitive to the specific method used to control for baseline differences or regional variations.

```{r robust-covariate-adj-models, echo=FALSE, message=FALSE, warning=FALSE}
# --- INTENT: Estimate DiD models replacing region FE with baseline covariates. ---
# --- EFFECT: Runs four lm() models using the original mig_long dataset. ---
message("Running Robustness Check 1: Covariate Adjustment Models...")

# Define baseline covariates (already in mig_long)
baseline_controls <- c("age", "educ", "male", "Score")
baseline_formula_part <- paste(baseline_controls, collapse = " + ")

# Ensure mig_long exists before proceeding
if (!exists("mig_long")) {
  stop("Error in robust-covariate-adj-models: mig_long data frame not found.")
}

# Model R1a: DiD (Baseline vs Wave 2, Weighted, Covariates)
asp.did.w2.cov <- lm(as.formula(paste("mg.asp ~ treat.dum*post.dum +", baseline_formula_part)),
                     data=subset(mig_long, wave!=3 & nonmissing2), # Use mig_long
                     weights=wt2)
# print(summary(asp.did.w2.cov)) # DEBUG PRINT REMOVED

# Model R1b: DiD (Baseline vs Wave 2, Unweighted, Covariates)
asp.did.w2.cov_unw <- lm(as.formula(paste("mg.asp ~ treat.dum*post.dum +", baseline_formula_part)),
                         data=subset(mig_long, wave!=3 & nonmissing2)) # Use mig_long
# print(summary(asp.did.w2.cov_unw)) # DEBUG PRINT REMOVED

# Model R1c: DiD (Baseline vs Wave 3, Weighted, Covariates)
asp.did.w3.cov <- lm(as.formula(paste("mg.asp ~ treat.dum*post.dum +", baseline_formula_part)),
                     data=subset(mig_long, wave!=2 & nonmissing3), # Use mig_long
                     weights=wt3)
# print(summary(asp.did.w3.cov)) # DEBUG PRINT REMOVED

# Model R1d: DiD (Baseline vs Wave 3, Unweighted, Covariates)
asp.did.w3.cov_unw <- lm(as.formula(paste("mg.asp ~ treat.dum*post.dum +", baseline_formula_part)),
                         data=subset(mig_long, wave!=2 & nonmissing3)) # Use mig_long
# print(summary(asp.did.w3.cov_unw)) # DEBUG PRINT REMOVED

message("Covariate adjustment models estimated.")
```

```{r robust-covariate-adj-table, echo=FALSE, fig.pos='H'}
# --- INTENT: Display the results of the covariate adjustment models. ---
# --- EFFECT: Uses modelsummary to create a table comparing original DiD models with covariate-adjusted models. ---
message("Generating table for Robustness Check 1...")

models_cov_adj <- list()
# Add models only if they exist (were estimated successfully previously)
if (exists("asp.did.w2") && !is.null(asp.did.w2)) models_cov_adj[["(2a) W2 DiD Wgt (FE)"]] <- asp.did.w2
if (exists("asp.did.w2.cov") && !is.null(asp.did.w2.cov)) models_cov_adj[["(R1a) W2 DiD Wgt (Cov)"]] <- asp.did.w2.cov
if (exists("asp.did.w2_unw") && !is.null(asp.did.w2_unw)) models_cov_adj[["(2b) W2 DiD Unw (FE)"]] <- asp.did.w2_unw
if (exists("asp.did.w2.cov_unw") && !is.null(asp.did.w2.cov_unw)) models_cov_adj[["(R1b) W2 DiD Unw (Cov)"]] <- asp.did.w2.cov_unw
if (exists("asp.did.w3") && !is.null(asp.did.w3)) models_cov_adj[["(4a) W3 DiD Wgt (FE)"]] <- asp.did.w3
if (exists("asp.did.w3.cov") && !is.null(asp.did.w3.cov)) models_cov_adj[["(R1c) W3 DiD Wgt (Cov)"]] <- asp.did.w3.cov
if (exists("asp.did.w3_unw") && !is.null(asp.did.w3_unw)) models_cov_adj[["(4b) W3 DiD Unw (FE)"]] <- asp.did.w3_unw
if (exists("asp.did.w3.cov_unw") && !is.null(asp.did.w3.cov_unw)) models_cov_adj[["(R1d) W3 DiD Unw (Cov)"]] <- asp.did.w3.cov_unw

# --- DEBUG --- 
# print(paste("Number of models found for Covariate Adjustment table:", length(models_cov_adj))) # EH: REMOVED
# --- END DEBUG ---

if (length(models_cov_adj) > 0) {
  coef_map_cov <- c("treat.dum" = "Treat assignment",
                    "post.dum" = "Post-treatment",
                    "treat.dum:post.dum" = "Treat x Post",
                    "age" = "Age",
                    "educ" = "Education",
                    "male" = "Male",
                    "Score" = "Score",
                    "(Intercept)" = "Constant")

  gof_map_cov <- list(
      list("raw" = "nobs", "clean" = "Observations", "fmt" = 0),
      list("raw" = "r.squared", "clean" = "R$^{2}$", "fmt" = 3),
      list("raw" = "adj.r.squared", "clean" = "Adj. R$^{2}$", "fmt" = 3)
  )

  modelsummary(models_cov_adj,
               output = "kableExtra",
               fmt = 3,
               stars = c("â€ " = 0.1, "*" = 0.05, "**" = 0.01, "***" = 0.001),
               coef_map = coef_map_cov,
               coef_omit = "^factor\\(Region\\)|^\\(Intercept\\)$", # Omit Region factors and Intercept
               gof_map = gof_map_cov,
               notes = list("Standard errors in parentheses.",
                          "FE models include Region Fixed Effects.",
                          "Cov models replace Region FE with baseline Age, Education, Male, Score."),
               title = "Robustness Check 1: Sensitivity to Covariate Adjustment vs. Region Fixed Effects",
               escape = FALSE
               ) %>%
    kable_styling(latex_options = c("striped", "hold_position", "scale_down"), # Added scale_down
                  bootstrap_options = "striped",
                  position = "center",
                  font_size = 9,
                  full_width = FALSE) %>%
    add_header_above(c(" " = 1, "Wave 2 Models" = 4, "Wave 3 Models" = 4)) %>% # Span headers
    column_spec(1, width = "6em")
} else {
  message("Skipping Covariate Adjustment table: No models available.")
}
```

**Summary of Covariate Adjustment Check:**
Difference-in-Differences (DiD) estimation relies on controlling for confounding factors to isolate the causal effect of the treatment. The primary analysis used regional fixed effects to account for unobserved time-invariant differences between regions. This robustness check assesses sensitivity to an alternative control strategy: replacing region fixed effects with observable baseline individual characteristics (`age`, `educ`, `male`, `Score`) that might otherwise lead to omitted variable bias. The results show that the estimated DiD treatment effect (`Treat x Post`) remains virtually unchanged in both magnitude and statistical significance across waves, regardless of whether regional fixed effects or these individual covariates are used. This strengthens confidence that the main findings are robust to different approaches for controlling potential confounders.
### 3. Placebo Test (Pre-Treatment Trends)

A placebo test typically involves examining trends *before* the intervention occurs. We would need at least two data points *before* the treatment began (e.g., Wave -1 and Wave 0) to run a DiD analysis where no effect is expected.

Based on the study timeline (**Figure 1** in the paper), data collection started with Wave 1 in Dec 2020/Jan 2021, *just before* the program began in Feb 2021. There are no pre-treatment waves available in the provided data (`mig_long` only contains waves 1, 2, 3).

**Therefore, a pre-treatment trend placebo test using the DiD framework is not feasible with the available data.** The baseline balance check (Table A1) serves as the primary method to assess pre-treatment comparability in this RCT context.

### 4. Heterogeneity of Treatment Effects (HTE)

Does the program effect differ for specific subgroups? We test this by interacting the treatment effect (`treat.dum:post.dum` in the DiD model) with key baseline characteristics available in `mig_long`: `male`, `educ`, and `bs.exp.now` (currently has business). We focus on the weighted Wave 2 DiD model where the main effect was strongest.

```{r robust-hte-models, echo=FALSE, message=FALSE, warning=FALSE}
# --- INTENT: Estimate DiD models with interaction terms for HTE using mig_long. ---
# --- EFFECT: Runs lm() models including triple interactions (treat*post*moderator). ---
message("Running Robustness Check 4: Heterogeneity of Treatment Effects (Interactions)...")

# Ensure mig_long exists
if (!exists("mig_long")) {
  stop("Error in robust-hte-models: mig_long data frame not found.")
}

# We use the Wave 2 dataset where effects were significant
data_w2_hte <- subset(mig_long, wave != 3 & nonmissing2) # Use mig_long

# Base formula part
base_hte_formula <- "mg.asp ~ treat.dum * post.dum * MODERATOR + factor(Region)"

# Function to create and run HTE model
run_hte_model <- function(moderator_var, data) {
  if (!moderator_var %in% names(data)) {
    message("Moderator variable '", moderator_var, "' not found. Skipping HTE for this variable.")
    return(NULL)
  }
  # Check for sufficient variation in moderator
  if (length(unique(na.omit(data[[moderator_var]]))) < 2) {
      message("Moderator variable '", moderator_var, "' has insufficient variation. Skipping HTE.")
      return(NULL)
  }

  formula_str <- gsub("MODERATOR", moderator_var, base_hte_formula)
  model <- tryCatch({
      lm(as.formula(formula_str), data = data, weights = wt2)
    }, error = function(e) {
      message("Error fitting HTE model for ", moderator_var, ": ", e$message); return(NULL)
  })
  # if (!is.null(model)) print(summary(model)) # DEBUG PRINT REMOVED
  return(model)
}

# Estimate models for each moderator (using variables confirmed in mig_long)
hte_male <- run_hte_model("male", data_w2_hte)
hte_educ <- run_hte_model("educ", data_w2_hte) # Treat educ as numeric/ordinal
hte_bs_exp <- run_hte_model("bs.exp.now", data_w2_hte)

message("HTE interaction models estimated (if data allowed).")
```

```{r robust-hte-table, echo=FALSE, fig.pos='H'}
# --- INTENT: Display results of the HTE models. ---
# --- EFFECT: Uses modelsummary, focusing on the triple interaction term. ---
message("Generating table for Robustness Check 4...")

models_hte <- list()
if (!is.null(hte_male)) models_hte[["Interact: Male"]] <- hte_male
if (!is.null(hte_educ)) models_hte[["Interact: Education"]] <- hte_educ
if (!is.null(hte_bs_exp)) models_hte[["Interact: Has Business"]] <- hte_bs_exp

# Add original model for reference only if it exists
if (exists("asp.did.w2") && !is.null(asp.did.w2)) models_hte[["(2a) Original W2 DiD Wgt"]] <- asp.did.w2

if (length(models_hte) > 1) { # Check if at least one HTE model ran + original
  coef_map_hte <- c(
    "treat.dum:post.dum" = "Treat x Post (Main Effect)",
    "treat.dum:post.dum:male" = "Treat x Post x Male",
    "treat.dum:post.dum:educ" = "Treat x Post x Education",
    "treat.dum:post.dum:bs.exp.now" = "Treat x Post x Has Business"
  )

  keep_pattern_hte <- "^treat\\.dum:post\\.dum" # Regex to keep key interactions

  gof_map_hte <- list(
    list("raw" = "nobs", "clean" = "Observations", "fmt" = 0),
    list("raw" = "r.squared", "clean" = "R$^{2}$", "fmt" = 3)
  )

  modelsummary(models_hte,
               output = "kableExtra",
               fmt = 3,
               stars = c("â€ " = 0.1, "*" = 0.05, "**" = 0.01, "***" = 0.001),
               coef_map = coef_map_hte,
               coef_matches = keep_pattern_hte,
               gof_map = gof_map_hte,
               notes = list("Standard errors in parentheses.",
                          "Models are weighted Wave 2 DiD specifications with Region FE.",
                          "Each interaction model adds a triple interaction term using baseline moderators.",
                          "Significance on the triple interaction suggests the treatment effect differs by the moderator."),
               title = "Robustness Check 4: Heterogeneity of Treatment Effects (Wave 2)",
               escape = FALSE
               ) %>%
    kable_styling(latex_options = c("striped", "hold_position"),
                  bootstrap_options = "striped",
                  position = "center",
                  font_size = 9,
                  full_width = FALSE) %>%
    column_spec(1, width = "12em")

} else {
  message("Skipping HTE table generation as no interaction models were successfully fitted or original model missing.")
}
```

**Summary of HTE Check:**
Causal effects often exhibit heterogeneity, meaning the impact of an intervention may differ across subgroups. The main DiD model estimates an average effect. This check explores potential heterogeneity by testing if the estimated treatment effect interacts significantly with observable baseline characteristics (`male`, `educ`, `bs.exp.now`). Specifically, we examine the triple interaction term (`Treat x Post x Moderator`) in the weighted Wave 2 DiD model. None of these interaction terms were statistically significant, suggesting that the average short-term treatment effect identified in the main analysis does not significantly differ across these specific subgroups. The estimated average dampening effect on migration aspirations appears relatively homogeneous in the short term with respect to gender, education, and prior business experience.



### 5. Clustered Standard Errors

Given that randomization was blocked by regional training site, we revisit our key DiD models with cluster-robust standard errors to account for potential correlation of errors within regions. We first assess the degree of intraclass correlation (ICC) within regions to determine whether clustering is justified.

```{r robust-cluster-icc, echo=FALSE, message=FALSE, warning=FALSE}
# Load necessary packages
library(lme4)  # For mixed effects models to calculate ICC

# Calculate ICC for Wave 2 model
calc_icc <- function(data, formula_str) {
  # Fit a mixed model with random intercept for region
  formula <- as.formula(paste(formula_str, "+ (1|Region)"))
  re_model <- lmer(formula, data=data)
  
  # Extract variance components
  vc <- VarCorr(re_model)
  region_var <- attr(vc$Region, "stddev")^2
  residual_var <- attr(vc, "sc")^2
  
  # Calculate ICC
  icc <- region_var / (region_var + residual_var)
  
  # Return ICC and model
  return(list(icc = icc, model = re_model))
}

# Calculate ICC for both waves
w2_icc_result <- calc_icc(
  subset(mig_long, wave!=3 & nonmissing2),
  "mg.asp ~ treat.dum*post.dum"
)

w3_icc_result <- calc_icc(
  subset(mig_long, wave!=2 & nonmissing3),
  "mg.asp ~ treat.dum*post.dum"
)

# Extract ICCs
w2_icc <- w2_icc_result$icc
w3_icc <- w3_icc_result$icc

# Create a table of ICCs
icc_table <- data.frame(
  Wave = c("Wave 2", "Wave 3"),
  ICC = c(w2_icc, w3_icc)
)

# Display ICC table with improved footnote
icc_table %>%
  kbl(
    caption = "Intraclass Correlation Coefficients (ICC) by Region",
    col.names = c("Analysis", "ICC"),
    digits = c(0, 3),
    align = c("l", "r"),
    booktabs = TRUE
  ) %>%
  kable_styling(
    latex_options = c("striped", "HOLD_position"), 
    bootstrap_options = "striped",
    position = "center",
    font_size = 9,
    full_width = FALSE
  ) %>%
  footnote(
    general = "ICC measures the proportion of variance attributable to regional clusters.",
    footnote_as_chunk = TRUE
  )
```

Based on the ICC values above, clustering the standard errors appears to be **not strongly justified**. Values above 0.05 typically warrant cluster adjustment, while values below 0.01 suggest minimal clustering effects. Indeed, our ICC values (0.009 for Wave 2, 0.004 for Wave 3) indicate very little within-region correlation in migration aspirations.

However, a curious disconnect emerges when we apply cluster-robust standard errors: despite minimal ICC values, we observe substantial increases in standard errors. This apparent contradiction stems from a well-known methodological challenge in econometrics: the "few clusters problem." With only three regions in our data (Greater Banjul Area, Lower River Region, Upper River Region), conventional cluster-robust standard errors become unreliable and typically biased upward, regardless of actual within-cluster correlation. Econometric literature recommends at least 10-15 clusters (preferably 30+) for reliable cluster-robust inference.

Nevertheless, we proceed with implementing cluster-robust standard errors to illustrate this methodological issue, while cautioning that the resulting significance changes may be artifacts of applying cluster adjustment with too few clusters rather than evidence of meaningful clustering effects.

```{r robust-clustered-se-simple, echo=FALSE, message=FALSE, warning=FALSE}
# Load necessary packages
library(sandwich)  # For robust standard errors
library(lmtest)    # For coeftest

# Define data subsets outside the function so they're available in the global environment
w2_data <- subset(mig_long, wave!=3 & nonmissing2)
w3_data <- subset(mig_long, wave!=2 & nonmissing3)

# Function to create a clean table directly
create_cluster_table <- function() {
  # Standard results for Wave 2
  w2_coef <- coef(summary(asp.did.w2))["treat.dum:post.dum", "Estimate"]
  w2_se <- coef(summary(asp.did.w2))["treat.dum:post.dum", "Std. Error"]
  w2_p <- coef(summary(asp.did.w2))["treat.dum:post.dum", "Pr(>|t|)"]
  
  # Clustered results for Wave 2
  w2_cl <- coeftest(asp.did.w2, vcov = vcovCL(asp.did.w2, cluster = w2_data$Region))
  w2_cl_se <- w2_cl["treat.dum:post.dum", "Std. Error"]
  w2_cl_p <- w2_cl["treat.dum:post.dum", "Pr(>|t|)"]
  
  # Standard results for Wave 3
  w3_coef <- coef(summary(asp.did.w3))["treat.dum:post.dum", "Estimate"]
  w3_se <- coef(summary(asp.did.w3))["treat.dum:post.dum", "Std. Error"]
  w3_p <- coef(summary(asp.did.w3))["treat.dum:post.dum", "Pr(>|t|)"]
  
  # Clustered results for Wave 3
  w3_cl <- coeftest(asp.did.w3, vcov = vcovCL(asp.did.w3, cluster = w3_data$Region))
  w3_cl_se <- w3_cl["treat.dum:post.dum", "Std. Error"]
  w3_cl_p <- w3_cl["treat.dum:post.dum", "Pr(>|t|)"]
  
  # Create table with basic R
  result <- data.frame(
    Model = c("Wave 2 DiD", "Wave 3 DiD"),
    Coef = round(c(w2_coef, w3_coef), 3),
    Std_SE = round(c(w2_se, w3_se), 3),
    Std_p = round(c(w2_p, w3_p), 3),
    Clust_SE = round(c(w2_cl_se, w3_cl_se), 3),
    Clust_p = round(c(w2_cl_p, w3_cl_p), 3),
    SE_Ratio = round(c(w2_cl_se/w2_se, w3_cl_se/w3_se), 2)
  )
  
  return(result)
}

# Create table and format with kable
cluster_table <- create_cluster_table()

# Format with kable and styling matching other tables
cluster_table %>%
  kbl(
    caption = "Effect of Regional Clustering on Standard Errors (DiD Treatment Effect)",
    col.names = c("Model", "Coefficient", "Standard SE", "Standard p", 
                 "Clustered SE", "Clustered p", "SE Ratio"),
    digits = c(0, 3, 3, 3, 3, 3, 2),
    align = c("l", "r", "r", "r", "r", "r", "r"),
    booktabs = TRUE
  ) %>%
  kable_styling(
    latex_options = c("striped", "HOLD_position"), 
    bootstrap_options = "striped",
    position = "center",
    font_size = 9,
    full_width = FALSE
  ) %>%
  footnote(
    general = "SE Ratio = Clustered SE / Standard SE. Wave 2 p-value changes from 0.009 to 0.056.",
    footnote_as_chunk = TRUE
  )

# For reference, also show the detailed coefficient info for Wave 2
# Store the detailed output to display it as formatted text
w2_std <- coef(summary(asp.did.w2))["treat.dum:post.dum",]
w2_robust <- coeftest(asp.did.w2, vcov = vcovCL(asp.did.w2, cluster = w2_data$Region))["treat.dum:post.dum",]

# Create a more formatted display of the key coefficient
coef_detail <- data.frame(
  "Estimator" = c("Conventional SE", "Cluster-robust SE"),
  "Estimate" = c(w2_std[1], w2_robust[1]),
  "Std.Error" = c(w2_std[2], w2_robust[2]),
  "t-value" = c(w2_std[3], w2_robust[3]),
  "p-value" = c(w2_std[4], w2_robust[4])
)

# Format the detailed comparison
coef_detail %>%
  kbl(
    caption = "Detailed Comparison for Wave 2 DiD 'Treat x Post' Coefficient",
    digits = c(0, 3, 3, 2, 3),
    align = c("l", "r", "r", "r", "r"),
    booktabs = TRUE
  ) %>%
  kable_styling(
    latex_options = c("striped", "HOLD_position"), 
    bootstrap_options = "striped",
    position = "center",
    font_size = 9,
    full_width = FALSE
  )
```

**Summary of Clustered Standard Errors Check:**
This robustness check addresses an important methodological concern regarding the clustered nature of the randomization design. As shown in the table, when we account for potential correlation of errors within regions by using cluster-robust standard errors, the statistical significance of our key findings changes.

For the Wave 2 model, the key interaction term "Treat Ã— Post" coefficient remains unchanged at approximately -0.301, indicating the program reduced migration aspirations by 0.3 points on the 5-point scale in the short term. However, the clustered standard error is larger than the conventional standard error, increasing the p-value from around 0.017 to 0.056. This means the short-term effect becomes only marginally significant at the p<0.1 level, rather than significant at the conventional p<0.05 level as in our main analysis.

This finding is particularly important given the original paper's emphasis on this short-term effect as primary evidence that foreign aid can reduce migration aspirations. The more conservative standard errors provided by clustering indicate that we should be more cautious about this conclusion, as the evidence for the short-term effect is weaker than previously suggested.

The Wave 3 results, which were already insignificant in our main analysis, remain insignificant with clustered standard errors, further supporting the conclusion about the transient nature of the program's effects.

```{r end-robustness-checks, echo=FALSE}
# --- End of Robustness Checks Section ---
message("Robustness check code sections added/corrected.")
```

## Discussion and Comparison with Original Paper

Our replication study largely confirms the core findings from Simon, Schwartz, and Hudson's original paper. Here we summarize the key comparisons between our replication results and the original study:

### Confirmation of Key Findings

1. Business outcomes: Our Table 1 replicates the pattern of significant positive treatment effects on all business outcomes except for business closure. Treatment group participants were substantially more likely to open businesses, make purchases, hire employees, and earn profits compared to the control group.

2. **Short-term migration aspirations: Our weighted DiD models in Table 2a yield almost identical treatment coefficients to the original paper (approximately -0.301), confirming the program's significant negative effect on migration aspirations in the short term (Wave 2).

3. Fading long-term effects**: Like the original paper, our results in Table 2b show the treatment effects on migration aspirations diminish by Wave 3 and lose statistical significance, supporting the authors' conclusion about the temporary nature of the intervention's impact.

4. Mediation through instrumental place attachment: Our Figures 2 and 3 corroborate that the program worked primarily through instrumental place attachment ("Financial success at home") rather than through self-efficacy or self-sufficiency, aligning with the authors' theoretical framework.

### Methodological Enhancements

Our replication extends the original analysis with several methodological refinements:

1. Weighting procedure robustness: By comparing weighted and unweighted DiD models (Tables 2a, 2b), we demonstrate that the main results are virtually identical regardless of whether inverse probability weighting is applied. This suggests that while methodologically sound, the original authors' complex weighting scheme had minimal practical impact on the estimates.

2. Alternative control strategies: Our covariate adjustment robustness check shows that replacing region fixed effects with individual-level covariates does not meaningfully alter the treatment effect estimates, strengthening confidence in the robustness of the results.

3. Ordered logit models: By modeling the ordinal nature of the migration aspiration outcome directly, we confirm the original findings aren't artifacts of treating an ordinal scale as continuous in the OLS models.

### Treatment Effect Heterogeneity

Our heterogeneity analysis finds mostly insignificant interaction terms, suggesting the program effects were relatively homogeneous across gender, education levels, and prior business experience. This finding augments the original paper by demonstrating broader applicability of the intervention across participant characteristics.

### Theoretical Implications

Our results reinforce the authors' theoretical focus on instrumental place attachment as the primary mechanism through which foreign aid can reduce migration aspirations. The finding that neither self-efficacy nor self-sufficiency significantly mediated migration aspirations, despite being improved by the program, supports the authors' contention that these traditional development outcomes are insufficient to change migration attitudes without also increasing place attachment.

### Limitations and Practical Considerations

The transient nature of the program's effects on migration aspirations, with significant impacts in Wave 2 that disappear by Wave 3, aligns with the qualitative insights from the original paper's interviews suggesting that maintaining instrumental place attachment requires ongoing support networks and continued assistance navigating bureaucratic barriers.

In conclusion, our replication supports the original paper's findings while providing additional evidence on robustness and generalizability. The results suggest that foreign aid interventions can temporarily reduce migration aspirations through instrumental place attachment, but sustaining these effects likely requires more persistent, structural interventions that address the broader institutional environment.

## Comparative Analysis of Treatment Effects

Our replication closely mirrors the treatment effects reported in the original paper, confirming their robustness. In the original study, Simon et al. found that the program reduced migration aspirations by approximately 0.30 points on their 5-point scale in the short term (Wave 2), with high statistical significance (p < 0.01). Our replicated Wave 2 DiD coefficient of -0.301 (p < 0.01) matches this finding almost exactly. Similarly, our Wave 3 DiD coefficient of -0.128 (not statistically significant) aligns with their reported finding that the effect "faded" over time.

This consistency is particularly noteworthy given three methodological differences in our approach:

1. We separated Wave 2 and Wave 3 results into different tables for clarity, while the original paper presented them together
2. We employed alternative statistical approaches including unweighted models and alternative control strategies
3. We applied multiple testing corrections (Hochberg method) to adjust for familywise error rate

The fact that our coefficients remain virtually identical across these different specifications underscores the original finding's robustness. The diminishing effect over time (from -0.301 to -0.128) also validates the authors' qualitative findings from interviews, which suggested that instrumental place attachment requires ongoing support networks and continued assistance navigating bureaucratic barriers to be sustained.
